{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker verification\n",
    "Implementation of a basic speaker classification system. It uses GMMS to model the speakers voice from MFCCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "plt.style.use('ggplot')\n",
    "rcParams['figure.figsize'] = 16, 8\n",
    "\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINICIO VARIABLES \n",
    "base_path = '/home/jc/speech_processing_notebooks'    #Carpeta practica 4\n",
    "speecon_path = os.path.join(base_path,'audios','speecon')    #Carpeta Speecon\n",
    "temp_path = os.path.join(base_path,'exports')    #Carpeta exports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc(files, n_coefs=16):\n",
    "    ''' Función genérica MFCC\n",
    "        Función genérica para calcular los coeficientes MFCC dada\n",
    "        una lista con los paths a los audios.\n",
    "        Utiliza la libreria librosa para leer el\n",
    "        audio y calcular los coeficientes.\n",
    "        Parametros:\n",
    "        - files: lista con los ficheros a computar\n",
    "        - n_coefs: int numero de coeficientes para el MFCC\n",
    "        Devuelve:\n",
    "        - base: np.array de tamaño Nxn_coefs con los coeficientes para cada trama'''\n",
    "    \n",
    "    #Inicializamos un array a ceros\n",
    "    base = np.zeros((1,n_coefs))\n",
    "    \n",
    "    for file_audio in files:\n",
    "        #Lectura del audio, remuestreamos a 8000Hz\n",
    "        audio, fs = librosa.core.load(file_audio, sr=8000)\n",
    "        #Calculo de los coefs\n",
    "        mfcc_raw = librosa.feature.mfcc(audio, sr=fs, n_mfcc=n_coefs).T\n",
    "        #Stack de la base de datos con los mfcc calculados\n",
    "        base = np.vstack((base,mfcc_raw))\n",
    "    \n",
    "    return base[1:] #El primero no lo devolvemos porqué son los ceros de inializacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mfcc(path):\n",
    "    ''' Reads mfcc file from person\n",
    "        Parametros:\n",
    "        - path: path donde leer el mfcc\n",
    "    '''\n",
    "    mfcc = np.loadtxt(path, delimiter=',')\n",
    "    \n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verification_list(speecon):\n",
    "    ''' Crea listas para calcular los parámetros posteriormente\n",
    "        Estructura listas:\n",
    "        - Hablantes entrenamiento (37.5%) : Son los audios que usamos para \n",
    "        entrenar el modelo GMM\n",
    "        - Hablantes testing (12.5%) : Son unos audios de las personas de entrenamiento\n",
    "        reservados para testing\n",
    "        - Impostores (50%): Son las personas que no pertenecen al sistema\n",
    "        Funcionamiento:\n",
    "        - Partimos el dataset en dos partes, personas correctas y personas incorrectas(impostores)\n",
    "        - Las personas correctas las partimos en 3/4 para entrenamiento y 1/4 parte testing\n",
    "        - Guardamos el path hacia los ficheros en listas\n",
    "    '''\n",
    "    #Diccionario para contener los datos\n",
    "    training = list()\n",
    "    testing_good = list()\n",
    "    impostor = list()\n",
    "    #count = 0\n",
    "    \n",
    "    # Iteramos la base de datos de speecon primero bloque a bloque \n",
    "    # y luego persona a persona\n",
    "    for block in os.listdir(speecon):\n",
    "        block_path = os.path.join(speecon,block)\n",
    "        \n",
    "        # Listamos todos los ficheros en el Block\n",
    "        ses_block = os.listdir(block_path)\n",
    "        # Los desordenamos\n",
    "        random.shuffle(ses_block)\n",
    "        \n",
    "        s = len(ses_block)\n",
    "        \n",
    "        # Y escojemos la mitad como usuarios buenos y la mitad como impostores\n",
    "        # (Usamos floor division para obtener numeros pares)\n",
    "        legit_users = ses_block[:s//2]\n",
    "        impostors = ses_block[s//2:(s//2)*2]\n",
    "        \n",
    "        \n",
    "        for user in legit_users:\n",
    "            ses_path = os.path.join(block_path,user)\n",
    "            \n",
    "            # Obtenemos los ficheros de la persona\n",
    "            all_files = glob.glob(f\"{ses_path}/*.wav\")\n",
    "            \n",
    "            # Para los users escojemos los 15 primeros ficheros (3/4) para training\n",
    "            # y los ultimos 5 (1/4) para testing.\n",
    "            train_files = all_files[:15]\n",
    "            test_files = all_files[-5:]\n",
    "            \n",
    "            # Añadimos a la base de datos\n",
    "            training.append(train_files)   #En los training es imortante tener una lista para cada hablante\n",
    "            testing_good.extend(test_files)\n",
    "        \n",
    "        for imp in impostors:\n",
    "            \n",
    "            # Path\n",
    "            ses_path = os.path.join(block_path,imp)\n",
    "            \n",
    "            # Para los impostores cojemos todos los ficheros para\n",
    "            # testing\n",
    "            all_files = glob.glob(f\"{ses_path}/*.wav\")\n",
    "            \n",
    "            # Extendemos la lista\n",
    "            impostor.extend(all_files)\n",
    "            \n",
    "    # Devolvemos una lista con las tres listas         \n",
    "    return [training, testing_good, impostor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mfccs(lists, n_coefs, train_path, test_good_path, test_bad_path):\n",
    "    ''' MFCCs Calculation\n",
    "        Calcula los MFCCs dadas unas listas con los paths a los ficheros de cada tipo\n",
    "        Parametros:\n",
    "        - lists: Lista con las tres listas de ficheros\n",
    "        - n_coefs: numero de coeficientes para calcular los mfccs\n",
    "        - train_path: Path donde guardar los ficheros de entrenamiento\n",
    "        - test_good_path: Path donde guardar los ficheros de testeo buenos\n",
    "        - test_bad_path: Path donde guardar los ficheros de testeo malos (impostores)\n",
    "    '''  \n",
    "    \n",
    "    # Comprovamos que las carpetas existan y si no las creamos\n",
    "    os.makedirs(train_path, exist_ok=True)\n",
    "    os.makedirs(test_bad_path, exist_ok=True)\n",
    "    os.makedirs(test_bad_path, exist_ok=True)\n",
    "    \n",
    "    training = lists[0]\n",
    "    testing_good = lists[1]\n",
    "    testing = lists[2]\n",
    "    \n",
    "    for path_list in training:\n",
    "        # Para calcular el modelo de la persona usamos todos los\n",
    "        # audios de train\n",
    "        train_mfcc = mfcc(path_list,n_coefs)\n",
    "        \n",
    "        # Extraemos el nombre de la persona a partir de la path\n",
    "        person = path_list[0][-10:-7]\n",
    "        \n",
    "        # Exportamos a csv\n",
    "        save_path = os.path.join(train_path, person+'.mfcc')\n",
    "        np.savetxt(save_path, train_mfcc, delimiter=\",\")\n",
    "    \n",
    "    print(\"Training MFCC calculated\")\n",
    "    \n",
    "    i = 0\n",
    "    for path in testing_good:\n",
    "        # Extraemos el nombre de la persona a partir de la path\n",
    "        person = path[-10:-7]\n",
    "        \n",
    "        # Creamos una carpeta para cada persona con sus audios,\n",
    "        # lo hacemos así para despues facilitar su validacion\n",
    "        os.makedirs(os.path.join(test_good_path, person), exist_ok=True)\n",
    "        save_path = os.path.join(test_good_path, person, f'audio{i}.mfcc')\n",
    "        \n",
    "        # Counter\n",
    "        i = i+1\n",
    "\n",
    "        # Calculo de los mfcc\n",
    "        test_mfcc = mfcc([path],n_coefs)\n",
    "        \n",
    "        # Exportamos a csv\n",
    "        np.savetxt(save_path, test_mfcc, delimiter=\",\")\n",
    "        \n",
    "    print(\"Good testing MFCC calculated\")\n",
    "       \n",
    "    i = 0\n",
    "    for path in testing:\n",
    "        # Extraemos el nombre de la persona a partir de la path\n",
    "        person = path[-10:-7]\n",
    "        \n",
    "        # Creamos una carpeta para cada persona con sus audios\n",
    "        os.makedirs(os.path.join(test_bad_path, person), exist_ok=True)\n",
    "        save_path = os.path.join(test_bad_path, person, f'audio{i}.mfcc')\n",
    "\n",
    "        # Counter\n",
    "        i = i+1\n",
    "        \n",
    "        # Calculo de los mfcc\n",
    "        test_mfcc = mfcc([path],n_coefs)\n",
    "        \n",
    "        #Exportamos a csv\n",
    "        np.savetxt(save_path, test_mfcc, delimiter=\",\")\n",
    "        \n",
    "    print(\"Impostor MFCC calculated\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gmm(n_gmms,train_path):\n",
    "    ''' Entrenamiento de las GMM\n",
    "        Parametros:\n",
    "        - n_gmms: Numero de coeficientes a usar para calcular el modelo GMM\n",
    "        - train_path: Path para leer los ficheros .csv con las MFCCs\n",
    "        Devuelve:\n",
    "        - trained_gmm: diccionario con los nombres y las GMMs\n",
    "    '''\n",
    "    # Lectura de los ficheros en la train_path\n",
    "    files_train = glob.glob(f\"{train_path}/*.mfcc\")\n",
    "    \n",
    "    trained_gmm = dict()\n",
    "    \n",
    "    for mfcc_path in files_train:\n",
    "        # Leemos los MFCCs para esa persona\n",
    "        mfcc = read_mfcc(mfcc_path)\n",
    "        \n",
    "        # Calculo de la GMM\n",
    "        gmm=GMM(n_gmms, n_init=2).fit(mfcc) \n",
    "        \n",
    "        # Extracción del nombre a partir del path\n",
    "        person = mfcc_path[-8:-5]\n",
    "        \n",
    "        # Guardamos gmm en el diccionario\n",
    "        trained_gmm[person] = gmm\n",
    "        \n",
    "    return trained_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_world_gmm(files_train, n_mfccs, n_gmms):\n",
    "    base = np.zeros((1,n_mfccs))\n",
    "\n",
    "    for mfcc_path in files_train:\n",
    "        mfcc = read_mfcc(mfcc_path)\n",
    "        #Stack de la base de datos con los mfcc calculados\n",
    "        base = np.vstack((base,mfcc))\n",
    "\n",
    "    gmm=GMM(n_gmms, n_init=2).fit(base)\n",
    "    \n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verification(trained_gmm, test_bad_path, test_good_path, world_gmm):\n",
    "    ''' Verification del locutor\n",
    "        Para cada hablante (una gmm por hablante) calcula la probabilidad de que \n",
    "        un conjunto de audios pertenezca a la persona. Para ese conjunto de audios\n",
    "        se escojen 5 audios que pertenecen a la persona y 5 que no.\n",
    "        Parametros:\n",
    "        - trained_gmm: diccionario con la gmm de cada persona\n",
    "        - test_bad_path: path donde encontrar los ficheros de testing malos (impostores)\n",
    "        - test_good_path: path donde encontrar los ficheros de testing buenos\n",
    "        Devuelve:\n",
    "        - assigned: diccionario con una lista de las scores de cada audio\n",
    "        las 5 primeras scores corresponden a audios de la gmm y los 5 siguientes no\n",
    "    '''\n",
    "    \n",
    "    # Contenedor de datos\n",
    "    assigned = dict()\n",
    "    \n",
    "    # Todos los ficheros impostores\n",
    "    all_test =  glob.glob(f\"{test_bad_path}/*/*.mfcc\")\n",
    "    # Shuffle para desordenar los ficheros y que salgan variados\n",
    "    random.shuffle(all_test)\n",
    "        \n",
    "    # Iteramos el diccionario. key = 'persona' gmm = gmm de la persona\n",
    "    for key, gmm in trained_gmm.items():\n",
    "        # Obtenemos los ficheros que corresponden\n",
    "        good_files = glob.glob(f\"{test_good_path}/{key}/*.mfcc\")\n",
    "        # Cojemos 5 ficheros de testing malos (impostores),\n",
    "        # como estan desordenados nos saldran ficheros de\n",
    "        # personas distintas\n",
    "        test_files = [all_test.pop() for i in range(0,5)]\n",
    "        \n",
    "        # Sanity check para comprobar que la carpeta no esta vacía\n",
    "        if len(good_files)==0: continue\n",
    "        \n",
    "        # Lista para guardar los datos\n",
    "        current_gmm = list()\n",
    "        \n",
    "        for path in good_files:\n",
    "            # Leemos mfcc\n",
    "            read = read_mfcc(path)\n",
    "            # Extraemos nombre de la persona a partir del path\n",
    "            person = path[42:45]\n",
    "            # Calculamos la score (logscore)\n",
    "            score = gmm.score(read)- world_gmm.score(read)\n",
    "            # Guardamos en el contenedor\n",
    "            current_gmm.append(score)\n",
    "        \n",
    "        for path in test_files:\n",
    "            # Leemos mfcc\n",
    "            read = read_mfcc(path)\n",
    "            # Extraemos nombre de la persona a partir del path\n",
    "            person = path[41:44]\n",
    "            # Calculamos la score (logscore)\n",
    "            score = gmm.score(read) - world_gmm.score(read)\n",
    "            # Guardamos en el contenedor\n",
    "            current_gmm.append(score)\n",
    "                \n",
    "        # Guardamos en el contenedor de datos\n",
    "        assigned[key] = current_gmm\n",
    "\n",
    "    return assigned\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_threshold(threshold, verification_dict):\n",
    "    ''' Calculo de las métricas para un determinado threshold\n",
    "        Parametros:\n",
    "        - threshold: valor del threshold\n",
    "        - verificatoin_dict: contenedor de resultados de la funcion\n",
    "        verification\n",
    "    '''\n",
    "    # Variables\n",
    "    missed = 0\n",
    "    false_positive = 0\n",
    "    count = 0\n",
    "    \n",
    "    # Iteramos todas las personas\n",
    "    for key,value in verification_dict.items():\n",
    "        i = 0\n",
    "        # Y por todos las scores\n",
    "        for l in value:\n",
    "            # Como los 5 primeros son buenos, miramos si es inferior\n",
    "            # al threshold. En caso afirmativo se comptabiliza como missed\n",
    "            if l<threshold and i<5: missed += 1\n",
    "                \n",
    "            # En los 5 segundos son impostores, miramos si superan el \n",
    "            # threshold. En caso afirmativo se comptabiliza como falso positivo\n",
    "            if l>threshold and i>5: false_positive += 1   \n",
    "            \n",
    "            # Counter de operaciones    \n",
    "            i = i + 1\n",
    "        \n",
    "        # Cuenta total de operaciones\n",
    "        count = count + i\n",
    "    \n",
    "    # Calculo del coste\n",
    "    cost = missed + false_positive*99\n",
    "    \n",
    "    # Presentación de resultados\n",
    "    print(f'TH: {threshold:.2f} | Missed: {missed:3}/{count} | False Positive: {false_positive:3}/{count} | Cost: {cost}')\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_threshold(verification_dict, starting_thr=-80, ending_thr=-50, step_thr=0.2):\n",
    "    ''' Busqueda de threshold óptimo\n",
    "        Calcula el threshold con el que conseguimos mejor coste.\n",
    "        Definimos coste como = missed + 99*false_positive\n",
    "        Parametros:\n",
    "        - verification_dict: diccionario devuelto por la funcion verification()\n",
    "        - starting_thr: Valor inicial de los thresholds evaluados\n",
    "        - ending_thr: Valor final de los threshold evaluados\n",
    "        - step_thr: Valor del step de los thresholds\n",
    "        Devuelve:\n",
    "        - thr: el mejor threshold para el modelo\n",
    "    '''\n",
    "    \n",
    "    # Constantes de análisis\n",
    "    cost_min = None\n",
    "    thr = None\n",
    "    \n",
    "    # Abanico de thresholds que vamos a probar\n",
    "    thr_array = np.arange(starting_thr, ending_thr, step_thr)\n",
    "    \n",
    "    # Iteramos todos los thresholds de thr_array\n",
    "    for threshold in thr_array:\n",
    "        # Usamos compute_threshold para calcular el coste del threshold\n",
    "        cost = compute_threshold(threshold, verification_dict)\n",
    "        \n",
    "        # Miramos si el coste baja con este thr, en caso afirmativo\n",
    "        # guardamos los datos\n",
    "        if cost_min == None or cost_min>cost:\n",
    "            cost_min = cost\n",
    "            thr = threshold\n",
    "        \n",
    "    # Resultados finales\n",
    "    print('\\nFinal results:')\n",
    "    compute_threshold(thr, v)\n",
    "            \n",
    "    return thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos paths donde exportar los ficheros de las MFCCs\n",
    "train_path = os.path.join(temp_path,'ver','train')\n",
    "test_good_path = os.path.join(temp_path,'ver','test_good')\n",
    "test_bad_path = os.path.join(temp_path,'ver','test_bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = verification_list(speecon_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MFCC calculated\n",
      "Good testing MFCC calculated\n",
      "Impostor MFCC calculated\n"
     ]
    }
   ],
   "source": [
    "compute_mfccs(lists, 17, train_path, test_good_path, test_bad_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-8676f7d2c084>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mworld_gmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_world_gmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfccs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_gmms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'files_train' is not defined"
     ]
    }
   ],
   "source": [
    "world_gmm = train_world_gmm(files_train, n_mfccs=17, n_gmms=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_gmm = train_gmm(8,train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si lanza error se tienen que recalcular los MFCCs\n",
    "v = verification(trained_gmm, test_bad_path, test_good_path, world_gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = find_threshold(v,-50,20,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
